{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b27106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio.Seq import Seq\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ef6a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Predict amino acid change\n",
    "def predict_aa_change(reference_seq, position, alt_base):\n",
    "    codon_start = (position // 3) * 3\n",
    "    ref_codon = reference_seq[codon_start:codon_start + 3]\n",
    "    alt_codon = ref_codon[:position % 3] + alt_base + ref_codon[position % 3 + 1:]\n",
    "    ref_aa = Seq(ref_codon).translate()\n",
    "    alt_aa = Seq(alt_codon).translate()\n",
    "    return f\"{ref_aa}{position//3 + 1}{alt_aa}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9268bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Classify variants as coding or non-coding\n",
    "def classify_variant(variant_position, gene_starts, gene_ends):\n",
    "    for start, end in zip(gene_starts, gene_ends):\n",
    "        if start <= variant_position <= end:\n",
    "            return \"Coding\"\n",
    "    return \"Non-coding\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527c80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify variants in regulatory regions\n",
    "def identify_regulatory_variants(variants, regulatory_regions):\n",
    "    regulatory_variants = []\n",
    "    for variant in variants:\n",
    "        for region_start, region_end, region_type in regulatory_regions:\n",
    "            if region_start <= variant['position'] <= region_end:\n",
    "                regulatory_variants.append({**variant, 'regulatory_type': region_type})\n",
    "                break\n",
    "    return regulatory_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef396a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Calculate SIFT score (simulated)\n",
    "def calculate_sift_score(reference_aa, alternate_aa):\n",
    "    # This is a simplified simulation of SIFT score calculation\n",
    "    amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "    if reference_aa == alternate_aa:\n",
    "        return 1.0\n",
    "    elif reference_aa in amino_acids and alternate_aa in amino_acids:\n",
    "        return random.uniform(0, 1)\n",
    "    else:\n",
    "        return 0.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb73985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Determine if variant causes frameshift\n",
    "def is_frameshift(ref_allele, alt_allele):\n",
    "    return abs(len(ref_allele) - len(alt_allele)) % 3 != 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e2d36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Annotate variants with gene names\n",
    "def annotate_with_gene_names(variants, gene_coords):\n",
    "    annotated_variants = []\n",
    "    for variant in variants:\n",
    "        for gene, (start, end) in gene_coords.items():\n",
    "            if start <= variant['position'] <= end:\n",
    "                annotated_variants.append({**variant, 'gene': gene})\n",
    "                break\n",
    "        else:\n",
    "            annotated_variants.append({**variant, 'gene': 'Intergenic'})\n",
    "    return annotated_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Predict impact of splice site variants\n",
    "def predict_splice_impact(variant, exon_starts, exon_ends):\n",
    "    for start, end in zip(exon_starts, exon_ends):\n",
    "        if variant['position'] in range(start - 2, start + 2) or variant['position'] in range(end - 1, end + 3):\n",
    "            return \"Potential splice site disruption\"\n",
    "    return \"No predicted splice site impact\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45c00ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Identify variants affecting transcription factor binding sites\n",
    "def identify_tfbs_variants(variants, tfbs_motifs):\n",
    "    tfbs_variants = []\n",
    "    for variant in variants:\n",
    "        for motif, sequence in tfbs_motifs.items():\n",
    "            ref_sequence = variant['ref_sequence']\n",
    "            alt_sequence = ref_sequence[:variant['position']] + variant['alt_allele'] + ref_sequence[variant['position']+1:]\n",
    "            if sequence in ref_sequence and sequence not in alt_sequence:\n",
    "                tfbs_variants.append({**variant, 'disrupted_tfbs': motif})\n",
    "            elif sequence not in ref_sequence and sequence in alt_sequence:\n",
    "                tfbs_variants.append({**variant, 'created_tfbs': motif})\n",
    "    return tfbs_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa82aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Calculate conservation score (simulated)\n",
    "def calculate_conservation_score(position, species_sequences):\n",
    "    # This is a simplified simulation of conservation score calculation\n",
    "    bases_at_position = [seq[position] for seq in species_sequences]\n",
    "    most_common = max(set(bases_at_position), key=bases_at_position.count)\n",
    "    conservation_score = bases_at_position.count(most_common) / len(species_sequences)\n",
    "    return conservation_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f96c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Integrate annotations from multiple sources\n",
    "def integrate_annotations(variants, gene_impacts, conservation_scores, regulatory_regions):\n",
    "    integrated_annotations = []\n",
    "    for variant in variants:\n",
    "        annotation = {\n",
    "            'position': variant['position'],\n",
    "            'ref_allele': variant['ref_allele'],\n",
    "            'alt_allele': variant['alt_allele'],\n",
    "            'gene_impact': gene_impacts.get(variant['position'], 'Unknown'),\n",
    "            'conservation_score': conservation_scores.get(variant['position'], 'Unknown'),\n",
    "            'regulatory_region': 'None'\n",
    "        }\n",
    "        for start, end, region_type in regulatory_regions:\n",
    "            if start <= variant['position'] <= end:\n",
    "                annotation['regulatory_region'] = region_type\n",
    "                break\n",
    "        integrated_annotations.append(annotation)\n",
    "    return integrated_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53eee0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Implement a machine learning model (e.g., Random Forest) to predict variant pathogenicity using features like conservation scores, allele frequencies, and protein impact scores. Use scikit-learn and evaluate the model's performance.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_pathogenicity_predictor(data_file):\n",
    "    # Load data\n",
    "    data = pd.read_csv(data_file)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = data[['conservation_score', 'allele_frequency', 'protein_impact_score']]\n",
    "    y = data['pathogenicity']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return clf, scaler\n",
    "\n",
    "# Example usage\n",
    "data_file = \"variant_data.csv\"\n",
    "model, scaler = train_pathogenicity_predictor(data_file)\n",
    "\n",
    "# Predict pathogenicity for new variants\n",
    "new_variants = pd.DataFrame({\n",
    "    'conservation_score': [0.8, 0.3, 0.9],\n",
    "    'allele_frequency': [0.001, 0.1, 0.0001],\n",
    "    'protein_impact_score': [0.7, 0.2, 0.95]\n",
    "})\n",
    "\n",
    "new_variants_scaled = scaler.transform(new_variants)\n",
    "predictions = model.predict(new_variants_scaled)\n",
    "\n",
    "print(\"Predictions for new variants:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0d9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create a function that integrates data from multiple omics layers (e.g., genomics, transcriptomics, epigenomics) to provide a comprehensive annotation for a given variant. Use pandas for data manipulation and numpy for numerical operations.\n",
    "import pandas as pd\n",
    "\n",
    "def integrate_omics_data(variant, genomic_data, transcriptomic_data, epigenomic_data):\n",
    "    integrated_annotation = {\n",
    "        'variant': variant,\n",
    "        'genomic_data': {},\n",
    "        'transcriptomic_data': {},\n",
    "        'epigenomic_data': {}\n",
    "    }\n",
    "    \n",
    "    # Genomic data integration\n",
    "    if variant in genomic_data:\n",
    "        integrated_annotation['genomic_data'] = {\n",
    "            'allele_frequency': genomic_data[variant]['allele_frequency'],\n",
    "            'conservation_score': genomic_data[variant]['conservation_score']\n",
    "        }\n",
    "    \n",
    "    # Transcriptomic data integration\n",
    "    gene = genomic_data[variant]['gene']\n",
    "    if gene in transcriptomic_data:\n",
    "        integrated_annotation['transcriptomic_data'] = {\n",
    "            'expression_level': transcriptomic_data[gene]['expression_level'],\n",
    "            'splicing_impact': transcriptomic_data[gene]['splicing_impact']\n",
    "        }\n",
    "    \n",
    "    # Epigenomic data integration\n",
    "    chrom, pos = variant.split(':')\n",
    "    pos = int(pos)\n",
    "    for region in epigenomic_data:\n",
    "        if region['chrom'] == chrom and region['start'] <= pos <= region['end']:\n",
    "            integrated_annotation['epigenomic_data'] = {\n",
    "                'chromatin_state': region['chromatin_state'],\n",
    "                'methylation_level': region['methylation_level']\n",
    "            }\n",
    "            break\n",
    "    \n",
    "    return integrated_annotation\n",
    "\n",
    "# Example usage\n",
    "genomic_data = {\n",
    "    'chr1:100': {'allele_frequency': 0.01, 'conservation_score': 0.9, 'gene': 'GENE1'},\n",
    "    'chr2:200': {'allele_frequency': 0.05, 'conservation_score': 0.5, 'gene': 'GENE2'}\n",
    "}\n",
    "\n",
    "transcriptomic_data = {\n",
    "    'GENE1': {'expression_level': 100, 'splicing_impact': 'high'},\n",
    "    'GENE2': {'expression_level': 50, 'splicing_impact': 'low'}\n",
    "}\n",
    "\n",
    "epigenomic_data = [\n",
    "    {'chrom': 'chr1', 'start': 1, 'end': 1000, 'chromatin_state': 'active', 'methylation_level': 0.2},\n",
    "    {'chrom': 'chr2', 'start': 1, 'end': 1000, 'chromatin_state': 'repressed', 'methylation_level': 0.8}\n",
    "]\n",
    "\n",
    "variant = 'chr1:100'\n",
    "integrated_annotation = integrate_omics_data(variant, genomic_data, transcriptomic_data, epigenomic_data)\n",
    "print(pd.json_normalize(integrated_annotation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dca8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Develop a visualization function that creates a lollipop plot showing the distribution and impact scores of variants along a gene sequence. Use matplotlib for plotting.\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_variant_lollipop(gene_length, variants, impact_scores):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot gene body\n",
    "    plt.plot([0, gene_length], [0, 0], color='gray', linewidth=2)\n",
    "    \n",
    "    # Plot variants as lollipops\n",
    "    plt.stem(variants, impact_scores, linefmt='C0-', markerfmt='C0o', basefmt=' ')\n",
    "    \n",
    "    plt.title(f'Variant Distribution and Impact Scores Along Gene Sequence')\n",
    "    plt.xlabel('Position in Gene Sequence')\n",
    "    plt.ylabel('Variant Impact Score')\n",
    "    plt.ylim(bottom=0)\n",
    "    plt.xlim(0, gene_length)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('variant_lollipop_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Variant lollipop plot saved as 'variant_lollipop_plot.png'\")\n",
    "\n",
    "# Example usage\n",
    "gene_length = 1000\n",
    "variants = [100, 250, 400, 600, 750, 900]\n",
    "impact_scores = [0.2, 0.8, 0.5, 0.9, 0.3, 0.7]\n",
    "\n",
    "plot_variant_lollipop(gene_length, variants, impact_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d768cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Implement a deep learning model using keras or pytorch to predict variant effects directly from DNA sequences. Include both convolutional and recurrent layers in your architecture.\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def encode_sequence(seq):\n",
    "    encoding = {'A': [1,0,0,0], 'C': [0,1,0,0], 'G': [0,0,1,0], 'T': [0,0,0,1]}\n",
    "    return np.array([encoding[base] for base in seq])\n",
    "\n",
    "def create_dataset(sequences, labels):\n",
    "    X = np.array([encode_sequence(seq) for seq in sequences])\n",
    "    y = to_categorical(labels)\n",
    "    return X, y\n",
    "\n",
    "def build_model(seq_length):\n",
    "    model = Sequential([\n",
    "        Conv1D(32, 3, activation='relu', input_shape=(seq_length, 4)),\n",
    "        MaxPooling1D(2),\n",
    "        Conv1D(64, 3, activation='relu'),\n",
    "        MaxPooling1D(2),\n",
    "        Flatten(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation='softmax')  # 3 classes: benign, pathogenic, VUS\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "sequences = [\n",
    "    'ATGCATGCATGC',\n",
    "    'GCTAGCTAGCTA',\n",
    "    'CGATCGATCGAT',\n",
    "    # ... more sequences ...\n",
    "]\n",
    "\n",
    "labels = [0, 1, 2, ...]  # 0: benign, 1: pathogenic, 2: VUS\n",
    "\n",
    "X, y = create_dataset(sequences, labels)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = build_model(seq_length=12)\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Predict effect of new variants\n",
    "new_sequences = [\n",
    "    'ATGCATGCATGC',\n",
    "    'GCTAGCTAGCTA',\n",
    "]\n",
    "new_X = np.array([encode_sequence(seq) for seq in new_sequences])\n",
    "predictions = model.predict(new_X)\n",
    "print(\"Predictions for new sequences:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62dbb8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Create a function that performs dimensionality reduction (e.g., PCA or t-SNE) on multi-omics data and visualizes the results, coloring points by variant pathogenicity. Use scikit-learn for dimensionality reduction and seaborn for visualization.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "def visualize_multi_omics_data(multi_omics_data, pathogenicity, method='pca'):\n",
    "    # Combine multi-omics data\n",
    "    combined_data = np.hstack([data for data in multi_omics_data.values()])\n",
    "    \n",
    "    # Perform dimensionality reduction\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "    elif method == 'tsne':\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported method. Choose 'pca' or 'tsne'.\")\n",
    "    \n",
    "    reduced_data = reducer.fit_transform(combined_data)\n",
    "    \n",
    "    # Create a dataframe for plotting\n",
    "    plot_data = pd.DataFrame({\n",
    "        'x': reduced_data[:, 0],\n",
    "        'y': reduced_data[:, 1],\n",
    "        'pathogenicity': pathogenicity\n",
    "    })\n",
    "    \n",
    "    # Plot the results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for category in plot_data['pathogenicity'].unique():\n",
    "        subset = plot_data[plot_data['pathogenicity'] == category]\n",
    "        plt.scatter(subset['x'], subset['y'], label=category, alpha=0.7)\n",
    "    \n",
    "    plt.title(f'Multi-omics Data Visualization using {method.upper()}')\n",
    "    plt.xlabel('Component 1')\n",
    "    plt.ylabel('Component 2')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'multi_omics_visualization_{method}.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Multi-omics visualization saved as 'multi_omics_visualization_{method}.png'\")\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulate multi-omics data\n",
    "n_samples = 1000\n",
    "multi_omics_data = {\n",
    "    'genomic': np.random.rand(n_samples, 10),\n",
    "    'transcriptomic': np.random.rand(n_samples, 15),\n",
    "    'epigenomic': np.random.rand(n_samples, 8)\n",
    "}\n",
    "\n",
    "# Simulate pathogenicity labels\n",
    "pathogenicity = np.random.choice(['benign', 'pathogenic', 'VUS'], n_samples)\n",
    "\n",
    "# Visualize using PCA\n",
    "visualize_multi_omics_data(multi_omics_data, pathogenicity, method='pca')\n",
    "\n",
    "# Visualize using t-SNE\n",
    "visualize_multi_omics_data(multi_omics_data, pathogenicity, method='tsne')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026c6ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# aa_change = predict_aa_change(\"ATGGCCTGA\", 3, \"C\")\n",
    "# variant_type = classify_variant(1000, [500, 2000], [1500, 2500])\n",
    "# reg_variants = identify_regulatory_variants([{'position': 100}, {'position': 200}], [(50, 150, 'promoter'), (180, 220, 'enhancer')])\n",
    "# sift_score = calculate_sift_score('A', 'V')\n",
    "# frameshift = is_frameshift('AT', 'A')\n",
    "# annotated_vars = annotate_with_gene_names([{'position': 1000}], {'Gene1': (500, 1500), 'Gene2': (2000, 2500)})\n",
    "# splice_impact = predict_splice_impact({'position': 1001}, [1000, 2000], [1500, 2500])\n",
    "# tfbs_vars = identify_tfbs_variants([{'position': 10, 'ref_sequence': 'ATCGATCG', 'alt_allele': 'G'}], {'TF1': 'GATC'})\n",
    "# cons_score = calculate_conservation_score(5, ['ATCGATCG', 'ATCTATCG', 'ATCGATCG'])\n",
    "# integrated_annot = integrate_annotations([{'position': 100, 'ref_allele': 'A', 'alt_allele': 'G'}], {100: 'Missense'}, {100: 0.9}, [(50, 150, 'promoter')])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
