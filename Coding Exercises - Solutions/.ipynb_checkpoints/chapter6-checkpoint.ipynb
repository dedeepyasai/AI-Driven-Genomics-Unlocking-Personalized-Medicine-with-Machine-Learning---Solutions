{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f8f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import norm\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65a743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Calculate average DNA methylation level\n",
    "def average_methylation(methylation_data, start, end):\n",
    "    region_data = methylation_data[(methylation_data['position'] >= start) & \n",
    "                                   (methylation_data['position'] <= end)]\n",
    "    return region_data['methylation'].mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7f1b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify differentially methylated regions\n",
    "def identify_dmrs(condition1, condition2, window_size=1000, step_size=100, p_threshold=0.05):\n",
    "    dmrs = []\n",
    "    for start in range(0, max(condition1['position'].max(), condition2['position'].max()), step_size):\n",
    "        end = start + window_size\n",
    "        region1 = condition1[(condition1['position'] >= start) & (condition1['position'] < end)]\n",
    "        region2 = condition2[(condition2['position'] >= start) & (condition2['position'] < end)]\n",
    "        if len(region1) > 0 and len(region2) > 0:\n",
    "            t_stat, p_value = stats.ttest_ind(region1['methylation'], region2['methylation'])\n",
    "            if p_value < p_threshold:\n",
    "                dmrs.append((start, end, t_stat, p_value))\n",
    "    return pd.DataFrame(dmrs, columns=['start', 'end', 't_statistic', 'p_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb1c059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize DNA methylation patterns\n",
    "def plot_methylation_heatmap(methylation_data, genes, window=1000):\n",
    "    matrix = []\n",
    "    for gene in genes:\n",
    "        start = gene['start'] - window\n",
    "        end = gene['end'] + window\n",
    "        region_data = methylation_data[(methylation_data['position'] >= start) & \n",
    "                                       (methylation_data['position'] <= end)]\n",
    "        matrix.append(region_data['methylation'].values)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(matrix, cmap='coolwarm', center=0.5)\n",
    "    plt.title('DNA Methylation Patterns')\n",
    "    plt.xlabel('Position relative to gene')\n",
    "    plt.ylabel('Genes')\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0617a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Classify CpG islands\n",
    "def classify_cpg_islands(cpg_data, threshold_low=0.3, threshold_high=0.7):\n",
    "    classifications = []\n",
    "    for _, cpg in cpg_data.iterrows():\n",
    "        if cpg['mean_methylation'] < threshold_low:\n",
    "            classifications.append('Hypomethylated')\n",
    "        elif cpg['mean_methylation'] > threshold_high:\n",
    "            classifications.append('Hypermethylated')\n",
    "        else:\n",
    "            classifications.append('Intermediate')\n",
    "    return pd.Series(classifications, index=cpg_data.index)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90a3003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Integrate methylation and gene expression data\n",
    "def integrate_methylation_expression(methylation_data, expression_data, window=1000):\n",
    "    integrated_data = []\n",
    "    for gene, expr in expression_data.items():\n",
    "        gene_methylation = methylation_data[(methylation_data['position'] >= gene['start'] - window) & \n",
    "                                            (methylation_data['position'] <= gene['end'] + window)]\n",
    "        mean_methylation = gene_methylation['methylation'].mean()\n",
    "        integrated_data.append((gene, mean_methylation, expr))\n",
    "    return pd.DataFrame(integrated_data, columns=['gene', 'mean_methylation', 'expression'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db20e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Peak calling for ChIP-seq data\n",
    "def call_peaks(chip_data, control_data, window_size=1000, fold_enrichment=4, p_threshold=1e-5):\n",
    "    peaks = []\n",
    "    for start in range(0, chip_data['position'].max(), window_size):\n",
    "        end = start + window_size\n",
    "        chip_counts = chip_data[(chip_data['position'] >= start) & (chip_data['position'] < end)]['counts'].sum()\n",
    "        control_counts = control_data[(control_data['position'] >= start) & (control_data['position'] < end)]['counts'].sum()\n",
    "        \n",
    "        if chip_counts > 0 and control_counts > 0:\n",
    "            fold_change = chip_counts / control_counts\n",
    "            p_value = stats.poisson.sf(chip_counts, control_counts)\n",
    "            \n",
    "            if fold_change >= fold_enrichment and p_value <= p_threshold:\n",
    "                peaks.append((start, end, fold_change, p_value))\n",
    "    \n",
    "    return pd.DataFrame(peaks, columns=['start', 'end', 'fold_change', 'p_value'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3cff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Calculate histone modification enrichment around TSS\n",
    "def histone_enrichment_tss(histone_data, tss_positions, window=5000):\n",
    "    enrichment = np.zeros(2 * window + 1)\n",
    "    for tss in tss_positions:\n",
    "        region_data = histone_data[(histone_data['position'] >= tss - window) & \n",
    "                                   (histone_data['position'] <= tss + window)]\n",
    "        region_data['relative_position'] = region_data['position'] - tss + window\n",
    "        enrichment += np.bincount(region_data['relative_position'], \n",
    "                                  weights=region_data['signal'], \n",
    "                                  minlength=2*window+1)\n",
    "    return enrichment / len(tss_positions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521298c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Identify bivalent chromatin domains\n",
    "def identify_bivalent_domains(activating_marks, repressing_marks, window_size=5000):\n",
    "    bivalent_domains = []\n",
    "    for start in range(0, max(activating_marks['position'].max(), repressing_marks['position'].max()), window_size):\n",
    "        end = start + window_size\n",
    "        activating = activating_marks[(activating_marks['position'] >= start) & (activating_marks['position'] < end)]\n",
    "        repressing = repressing_marks[(repressing_marks['position'] >= start) & (repressing_marks['position'] < end)]\n",
    "        \n",
    "        if activating['signal'].sum() > 0 and repressing['signal'].sum() > 0:\n",
    "            bivalent_domains.append((start, end))\n",
    "    \n",
    "    return pd.DataFrame(bivalent_domains, columns=['start', 'end'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f5b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Predict enhancer regions\n",
    "def predict_enhancers(h3k4me1_data, h3k27ac_data, window_size=1000, threshold=0.8):\n",
    "    enhancers = []\n",
    "    for start in range(0, max(h3k4me1_data['position'].max(), h3k27ac_data['position'].max()), window_size):\n",
    "        end = start + window_size\n",
    "        h3k4me1 = h3k4me1_data[(h3k4me1_data['position'] >= start) & (h3k4me1_data['position'] < end)]\n",
    "        h3k27ac = h3k27ac_data[(h3k27ac_data['position'] >= start) & (h3k27ac_data['position'] < end)]\n",
    "        \n",
    "        if h3k4me1['signal'].mean() > threshold and h3k27ac['signal'].mean() > threshold:\n",
    "            enhancers.append((start, end))\n",
    "    \n",
    "    return pd.DataFrame(enhancers, columns=['start', 'end'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ff744e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Simulate DNA methylation data\n",
    "def simulate_methylation_data(n_regions=1000, n_cpgs_per_region=20):\n",
    "    methylation_data = []\n",
    "    for i in range(n_regions):\n",
    "        start = i * 1000\n",
    "        cpg_positions = np.sort(np.random.choice(range(start, start+1000), n_cpgs_per_region, replace=False))\n",
    "        methylation_levels = np.random.beta(1, 1, n_cpgs_per_region)\n",
    "        for pos, meth in zip(cpg_positions, methylation_levels):\n",
    "            methylation_data.append((pos, meth))\n",
    "    \n",
    "    return pd.DataFrame(methylation_data, columns=['position', 'methylation'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73353df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Implement a function to perform peak calling on ATAC-seq data and visualize the distribution of peaks relative to transcription start sites.\n",
    "import pybedtools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "def call_atac_peaks(bam_file, genome, output_file):\n",
    "    \"\"\"\n",
    "    Perform peak calling on ATAC-seq data using MACS2.\n",
    "    \n",
    "    Parameters:\n",
    "    bam_file (str): Path to the BAM file containing aligned ATAC-seq reads\n",
    "    genome (str): Genome size (e.g., 'hs' for human, 'mm' for mouse)\n",
    "    output_file (str): Path to save the called peaks\n",
    "    \n",
    "    Returns:\n",
    "    pybedtools.BedTool: Called peaks\n",
    "    \"\"\"\n",
    "    peaks = pybedtools.BedTool(bam_file).sort().bam_to_bed().slop(g=genome, b=100).merge()\n",
    "    peaks = peaks.filter(lambda x: int(x.end) - int(x.start) > 50)\n",
    "    peaks.saveas(output_file)\n",
    "    return peaks\n",
    "\n",
    "def visualize_peak_distribution(peaks, tss_file, output_file):\n",
    "    \"\"\"\n",
    "    Visualize the distribution of ATAC-seq peaks relative to transcription start sites.\n",
    "    \n",
    "    Parameters:\n",
    "    peaks (pybedtools.BedTool): Called ATAC-seq peaks\n",
    "    tss_file (str): Path to the BED file containing transcription start sites\n",
    "    output_file (str): Path to save the output plot\n",
    "    \"\"\"\n",
    "    tss = pybedtools.BedTool(tss_file)\n",
    "    distances = []\n",
    "    \n",
    "    for peak in peaks:\n",
    "        nearest_tss = tss.closest(peak, d=True)[0]\n",
    "        distance = int(nearest_tss[-1])\n",
    "        if nearest_tss.strand == '-':\n",
    "            distance = -distance\n",
    "        distances.append(distance)\n",
    "    \n",
    "    distances = np.array(distances)\n",
    "    distances = distances[np.abs(distances) <= 5000]  # Limit to +/- 5kb\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    density = gaussian_kde(distances)\n",
    "    xs = np.linspace(-5000, 5000, 200)\n",
    "    plt.plot(xs, density(xs))\n",
    "    plt.title('Distribution of ATAC-seq Peaks Relative to TSS')\n",
    "    plt.xlabel('Distance to TSS (bp)')\n",
    "    plt.ylabel('Density')\n",
    "    plt.axvline(x=0, color='r', linestyle='--', label='TSS')\n",
    "    plt.legend()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "\n",
    "# Example usage\n",
    "bam_file = \"atac_seq_aligned.bam\"\n",
    "genome = \"hg38\"\n",
    "peak_file = \"atac_peaks.bed\"\n",
    "tss_file = \"transcription_start_sites.bed\"\n",
    "\n",
    "peaks = call_atac_peaks(bam_file, genome, peak_file)\n",
    "visualize_peak_distribution(peaks, tss_file, \"atac_peak_distribution.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3edded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create a script to analyze Hi-C data and identify topologically associating domains (TADs) using the insulation score method.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cooler\n",
    "\n",
    "def calculate_insulation_score(matrix, window_size=5):\n",
    "    \"\"\"\n",
    "    Calculate the insulation score for a Hi-C contact matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    matrix (np.array): Hi-C contact matrix\n",
    "    window_size (int): Size of the sliding window\n",
    "    \n",
    "    Returns:\n",
    "    np.array: Insulation scores\n",
    "    \"\"\"\n",
    "    n = matrix.shape[0]\n",
    "    scores = np.zeros(n)\n",
    "    \n",
    "    for i in range(window_size, n - window_size):\n",
    "        window = matrix[i-window_size:i+window_size, i-window_size:i+window_size]\n",
    "        scores[i] = np.mean(window)\n",
    "    \n",
    "    return scores\n",
    "\n",
    "def call_tads(insulation_scores, min_size=5):\n",
    "    \"\"\"\n",
    "    Call TADs based on insulation scores.\n",
    "    \n",
    "    Parameters:\n",
    "    insulation_scores (np.array): Insulation scores\n",
    "    min_size (int): Minimum size of a TAD in bins\n",
    "    \n",
    "    Returns:\n",
    "    list: List of TAD boundaries\n",
    "    \"\"\"\n",
    "    local_minima = (insulation_scores[1:-1] < insulation_scores[:-2]) & \\\n",
    "                   (insulation_scores[1:-1] < insulation_scores[2:])\n",
    "    boundaries = np.where(local_minima)[0] + 1\n",
    "    \n",
    "    tads = []\n",
    "    for i in range(len(boundaries) - 1):\n",
    "        if boundaries[i+1] - boundaries[i] >= min_size:\n",
    "            tads.append((boundaries[i], boundaries[i+1]))\n",
    "    \n",
    "    return tads\n",
    "\n",
    "def analyze_hic_data(cool_file, chromosome, resolution, output_file):\n",
    "    \"\"\"\n",
    "    Analyze Hi-C data to identify TADs and visualize the results.\n",
    "    \n",
    "    Parameters:\n",
    "    cool_file (str): Path to the .cool file containing Hi-C data\n",
    "    chromosome (str): Chromosome to analyze\n",
    "    resolution (int): Resolution of the Hi-C data in base pairs\n",
    "    output_file (str): Path to save the output plot\n",
    "    \"\"\"\n",
    "    # Load Hi-C data\n",
    "    c = cooler.Cooler(cool_file)\n",
    "    matrix = c.matrix(balance=True).fetch(chromosome)\n",
    "    \n",
    "    # Calculate insulation scores\n",
    "    insulation_scores = calculate_insulation_score(matrix)\n",
    "    \n",
    "    # Call TADs\n",
    "    tads = call_tads(insulation_scores)\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot Hi-C matrix\n",
    "    im = ax1.imshow(np.log1p(matrix), cmap='YlOrRd', aspect='auto')\n",
    "    ax1.set_title(f'Hi-C Contact Matrix - {chromosome}')\n",
    "    plt.colorbar(im, ax=ax1, label='Log(Contact Frequency + 1)')\n",
    "    \n",
    "    # Plot insulation score\n",
    "    ax2.plot(insulation_scores)\n",
    "    ax2.set_title('Insulation Score')\n",
    "    ax2.set_xlabel('Genomic Position (bins)')\n",
    "    ax2.set_ylabel('Insulation Score')\n",
    "    \n",
    "    # Highlight TADs\n",
    "    for start, end in tads:\n",
    "        ax1.axvline(x=start, color='blue', linestyle='--', alpha=0.5)\n",
    "        ax1.axvline(x=end, color='blue', linestyle='--', alpha=0.5)\n",
    "        ax2.axvline(x=start, color='blue', linestyle='--', alpha=0.5)\n",
    "        ax2.axvline(x=end, color='blue', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "    return tads\n",
    "\n",
    "# Example usage\n",
    "cool_file = \"hic_data.cool\"\n",
    "chromosome = \"chr1\"\n",
    "resolution = 25000  # 25 kb resolution\n",
    "tads = analyze_hic_data(cool_file, chromosome, resolution, \"hic_tad_analysis.png\")\n",
    "\n",
    "print(f\"Number of TADs identified: {len(tads)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a01ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Develop a program to calculate and visualize A/B compartments from Hi-C data using principal component analysis.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cooler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def calculate_ab_compartments(cool_file, chromosome, resolution, output_file):\n",
    "    \"\"\"\n",
    "    Calculate and visualize A/B compartments from Hi-C data using PCA.\n",
    "    \n",
    "    Parameters:\n",
    "    cool_file (str): Path to the .cool file containing Hi-C data\n",
    "    chromosome (str): Chromosome to analyze\n",
    "    resolution (int): Resolution of the Hi-C data in base pairs\n",
    "    output_file (str): Path to save the output plot\n",
    "    \n",
    "    Returns:\n",
    "    np.array: First principal component (PC1) values\n",
    "    \"\"\"\n",
    "    # Load Hi-C data\n",
    "    c = cooler.Cooler(cool_file)\n",
    "    matrix = c.matrix(balance=True).fetch(chromosome)\n",
    "    \n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = np.corrcoef(matrix)\n",
    "    corr_matrix = np.nan_to_num(corr_matrix)\n",
    "    \n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=1)\n",
    "    pc1 = pca.fit_transform(corr_matrix).flatten()\n",
    "    \n",
    "    # Ensure positive values correspond to A compartments\n",
    "    if np.sum(pc1[pc1 > 0]) < np.sum(pc1[pc1 < 0]):\n",
    "        pc1 = -pc1\n",
    "    \n",
    "    # Visualize results\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10), sharex=True)\n",
    "    \n",
    "    # Plot Hi-C matrix\n",
    "    im = ax1.imshow(np.log1p(matrix), cmap='YlOrRd', aspect='auto')\n",
    "    ax1.set_title(f'Hi-C Contact Matrix - {chromosome}')\n",
    "    plt.colorbar(im, ax=ax1, label='Log(Contact Frequency + 1)')\n",
    "    \n",
    "    # Plot PC1 values\n",
    "    ax2.plot(pc1)\n",
    "    ax2.set_title('A/B Compartments (PC1)')\n",
    "    ax2.set_xlabel('Genomic Position (bins)')\n",
    "    ax2.set_ylabel('PC1 Value')\n",
    "    ax2.axhline(y=0, color='r', linestyle='--')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "    return pc1\n",
    "\n",
    "# Example usage\n",
    "cool_file = \"hic_data.cool\"\n",
    "chromosome = \"chr1\"\n",
    "resolution = 100000  # 100 kb resolution\n",
    "pc1 = calculate_ab_compartments(cool_file, chromosome, resolution, \"ab_compartments.png\")\n",
    "\n",
    "# Classify regions into A and B compartments\n",
    "a_compartments = np.where(pc1 > 0)[0]\n",
    "b_compartments = np.where(pc1 < 0)[0]\n",
    "\n",
    "print(f\"Number of A compartment regions: {len(a_compartments)}\")\n",
    "print(f\"Number of B compartment regions: {len(b_compartments)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22587922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Write a function to implement a basic epigenetic clock model using DNA methylation data and chronological age information.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train_epigenetic_clock(methylation_data, ages, n_cpgs=100, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Train an epigenetic clock model using DNA methylation data.\n",
    "    \n",
    "    Parameters:\n",
    "    methylation_data (pd.DataFrame): DNA methylation data (CpG sites x samples)\n",
    "    ages (pd.Series): Chronological ages of the samples\n",
    "    n_cpgs (int): Number of CpG sites to use in the model\n",
    "    test_size (float): Proportion of data to use for testing\n",
    "    \n",
    "    Returns:\n",
    "    tuple: Trained model, selected CpG sites, and evaluation metrics\n",
    "    \"\"\"\n",
    "    # Select most variable CpG sites\n",
    "    var_cpgs = methylation_data.var().nlargest(n_cpgs).index\n",
    "    X = methylation_data[var_cpgs]\n",
    "    \n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, ages, test_size=test_size, random_state=42)\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = model.predict(X_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    \n",
    "    # Visualize results\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    plt.xlabel('Chronological Age')\n",
    "    plt.ylabel('Predicted Age')\n",
    "    plt.title('Epigenetic Clock: Predicted vs Chronological Age')\n",
    "    plt.text(0.05, 0.95, f'MAE: {mae:.2f}\\nRMSE: {rmse:.2f}', transform=plt.gca().transAxes)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('epigenetic_clock.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return model, var_cpgs, {'MAE': mae, 'RMSE': rmse}\n",
    "\n",
    "# Example usage\n",
    "# Generate synthetic methylation data and ages\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_cpgs = 10000\n",
    "methylation_data = pd.DataFrame(np.random.beta(1, 1, size=(n_cpgs, n_samples)))\n",
    "ages = pd.Series(np.random.uniform(20, 80, n_samples))\n",
    "\n",
    "model, selected_cpgs, metrics = train_epigenetic_clock(methylation_data, ages)\n",
    "\n",
    "print(\"Selected CpG sites:\", selected_cpgs)\n",
    "print(\"Model performance:\")\n",
    "print(f\"MAE: {metrics['MAE']:.2f}\")\n",
    "print(f\"RMSE: {metrics['RMSE']:.2f}\")\n",
    "\n",
    "# Predict age for new samples\n",
    "new_samples = pd.DataFrame(np.random.beta(1, 1, size=(n_cpgs, 5)))\n",
    "predicted_ages = model.predict(new_samples.loc[selected_cpgs])\n",
    "print(\"Predicted ages for new samples:\", predicted_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be727e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Implement a script to integrate chromatin accessibility data with long-range interaction data to identify potential enhancer-promoter interactions.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "def integrate_accessibility_interactions(accessibility_data, interaction_data, gene_annotations, output_file):\n",
    "    \"\"\"\n",
    "    Integrate chromatin accessibility data with long-range interaction data to identify\n",
    "    potential enhancer-promoter interactions.\n",
    "    \n",
    "    Parameters:\n",
    "    accessibility_data (pd.DataFrame): ATAC-seq peak data (columns: chrom, start, end, score)\n",
    "    interaction_data (pd.DataFrame): Hi-C interaction data (columns: chrom1, start1, end1, chrom2, start2, end2, score)\n",
    "    gene_annotations (pd.DataFrame): Gene annotations (columns: chrom, start, end, gene_name, strand)\n",
    "    output_file (str): Path to save the output plot\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Potential enhancer-promoter interactions\n",
    "    \"\"\"\n",
    "    # Function to check if two regions overlap\n",
    "    def regions_overlap(start1, end1, start2, end2):\n",
    "        return start1 <= end2 and start2 <= end1\n",
    "    \n",
    "    # Identify potential enhancers (ATAC-seq peaks not overlapping promoters)\n",
    "    promoter_region = 2000  # Define promoter as 2kb upstream of TSS\n",
    "    enhancers = []\n",
    "    for _, peak in accessibility_data.iterrows():\n",
    "        is_enhancer = True\n",
    "        for _, gene in gene_annotations.iterrows():\n",
    "            if gene['strand'] == '+':\n",
    "                promoter_start, promoter_end = gene['start'] - promoter_region, gene['start']\n",
    "            else:\n",
    "                promoter_start, promoter_end = gene['end'], gene['end'] + promoter_region\n",
    "            \n",
    "            if regions_overlap(peak['start'], peak['end'], promoter_start, promoter_end):\n",
    "                is_enhancer = False\n",
    "                break\n",
    "        \n",
    "        if is_enhancer:\n",
    "            enhancers.append(peak)\n",
    "    \n",
    "    enhancers = pd.DataFrame(enhancers)\n",
    "    \n",
    "    # Identify potential enhancer-promoter interactions\n",
    "    potential_interactions = []\n",
    "    for _, enhancer in enhancers.iterrows():\n",
    "        for _, interaction in interaction_data.iterrows():\n",
    "            if regions_overlap(enhancer['start'], enhancer['end'], interaction['start1'], interaction['end1']):\n",
    "                for _, gene in gene_annotations.iterrows():\n",
    "                    if regions_overlap(gene['start'], gene['end'], interaction['start2'], interaction['end2']):\n",
    "                        potential_interactions.append({\n",
    "                            'enhancer_chrom': enhancer['chrom'],\n",
    "                            'enhancer_start': enhancer['start'],\n",
    "                            'enhancer_end': enhancer['end'],\n",
    "                            'enhancer_score': enhancer['score'],\n",
    "                            'gene_name': gene['gene_name'],\n",
    "                            'gene_start': gene['start'],\n",
    "                            'gene_end': gene['end'],\n",
    "                            'interaction_score': interaction['score']\n",
    "                        })\n",
    "    \n",
    "    potential_interactions = pd.DataFrame(potential_interactions)\n",
    "    \n",
    "    # Visualize potential enhancer-promoter interactions\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(potential_interactions['enhancer_score'], potential_interactions['interaction_score'], alpha=0.5)\n",
    "    plt.xlabel('Enhancer Accessibility Score')\n",
    "    plt.ylabel('Interaction Score')\n",
    "    plt.title('Potential Enhancer-Promoter Interactions')\n",
    "    \n",
    "    for _, interaction in potential_interactions.iterrows():\n",
    "        plt.annotate(interaction['gene_name'], \n",
    "                     (interaction['enhancer_score'], interaction['interaction_score']),\n",
    "                     xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()\n",
    "    \n",
    "    return potential_interactions\n",
    "\n",
    "# Example usage\n",
    "accessibility_data = pd.DataFrame({\n",
    "    'chrom': ['chr1', 'chr1', 'chr2', 'chr2'],\n",
    "    'start': [1000, 5000, 2000, 8000],\n",
    "    'end': [2000, 6000, 3000, 9000],\n",
    "    'score': [10, 15, 8, 12]\n",
    "})\n",
    "\n",
    "interaction_data = pd.DataFrame({\n",
    "    'chrom1': ['chr1', 'chr1', 'chr2'],\n",
    "    'start1': [1500, 5500, 2500],\n",
    "    'end1': [2500, 6500, 3500],\n",
    "    'chrom2': ['chr1', 'chr1', 'chr2'],\n",
    "    'start2': [10000, 15000, 12000],\n",
    "    'end2': [11000, 16000, 13000],\n",
    "    'score': [0.8, 0.6, 0.7]\n",
    "})\n",
    "\n",
    "gene_annotations = pd.DataFrame({\n",
    "    'chrom': ['chr1', 'chr1', 'chr2'],\n",
    "    'start': [9500, 14500, 11500],\n",
    "    'end': [11500, 16500, 13500],\n",
    "    'gene_name': ['Gene1', 'Gene2', 'Gene3'],\n",
    "    'strand': ['+', '-', '+']\n",
    "})\n",
    "\n",
    "output_file = 'enhancer_promoter_interactions.png'\n",
    "\n",
    "potential_interactions = integrate_accessibility_interactions(accessibility_data, interaction_data, gene_annotations, output_file)\n",
    "print(potential_interactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25dd616",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# methylation_data = simulate_methylation_data()\n",
    "# avg_methylation = average_methylation(methylation_data, 1000, 2000)\n",
    "\n",
    "# condition1 = simulate_methylation_data()\n",
    "# condition2 = simulate_methylation_data()\n",
    "# dmrs = identify_dmrs(condition1, condition2)\n",
    "\n",
    "# genes = [{'start': 1000, 'end': 2000}, {'start': 3000, 'end': 4000}]\n",
    "# plot_methylation_heatmap(methylation_data, genes)\n",
    "\n",
    "# cpg_islands = pd.DataFrame({'mean_methylation': np.random.uniform(0, 1, 100)})\n",
    "# cpg_classifications = classify_cpg_islands(cpg_islands)\n",
    "\n",
    "# expression_data = {'gene1': 10, 'gene2': 20}\n",
    "# integrated_data = integrate_methylation_expression(methylation_data, expression_data)\n",
    "\n",
    "# chip_data = pd.DataFrame({'position': range(10000), 'counts': np.random.poisson(10, 10000)})\n",
    "# control_data = pd.DataFrame({'position': range(10000), 'counts': np.random.poisson(5, 10000)})\n",
    "# peaks = call_peaks(chip_data, control_data)\n",
    "\n",
    "# tss_positions = [1000, 3000, 5000]\n",
    "# histone_data = pd.DataFrame({'position': range(10000), 'signal': np.random.poisson(5, 10000)})\n",
    "# enrichment = histone_enrichment_tss(histone_data, tss_positions)\n",
    "\n",
    "# activating_marks = pd.DataFrame({'position': range(10000), 'signal': np.random.poisson(5, 10000)})\n",
    "# repressing_marks = pd.DataFrame({'position': range(10000), 'signal': np.random.poisson(5, 10000)})\n",
    "# bivalent_domains = identify_bivalent_domains(activating_marks, repressing_marks)\n",
    "\n",
    "# h3k4me1_data = pd.DataFrame({'position': range(10000), 'signal': np.random.uniform(0, 1, 10000)})\n",
    "# h3k27ac_data = pd.DataFrame({'position': range(10000), 'signal': np.random.uniform(0, 1, 10000)})\n",
    "# enhancers = predict_enhancers(h3k4me1_data, h3k27ac_data)\n",
    "\n",
    "# simulated_methylation = simulate_methylation_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
