{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f755b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vcf\n",
    "from collections import defaultdict\n",
    "import random\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b455fbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Parse VCF file\n",
    "def parse_vcf(vcf_file):\n",
    "    variants = []\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    for record in vcf_reader:\n",
    "        variants.append({\n",
    "            'CHROM': record.CHROM,\n",
    "            'POS': record.POS,\n",
    "            'REF': record.REF,\n",
    "            'ALT': str(record.ALT[0]),\n",
    "            'QUAL': record.QUAL\n",
    "        })\n",
    "    return variants\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ab265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate allele frequencies\n",
    "def calculate_allele_frequencies(vcf_file):\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    frequencies = {}\n",
    "    for record in vcf_reader:\n",
    "        if record.samples[0].gt_type is not None:\n",
    "            alt_freq = sum(s.gt_type for s in record.samples if s.gt_type is not None) / (2 * len(record.samples))\n",
    "            frequencies[f\"{record.CHROM}:{record.POS}\"] = alt_freq\n",
    "    return frequencies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3943f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Filter variants based on quality\n",
    "def filter_variants_by_quality(vcf_file, quality_threshold):\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    filtered_variants = [record for record in vcf_reader if record.QUAL >= quality_threshold]\n",
    "    return filtered_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e66d8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Identify unique variants\n",
    "def find_unique_variants(vcf_files):\n",
    "    variant_counts = defaultdict(int)\n",
    "    unique_variants = defaultdict(list)\n",
    "    \n",
    "    for i, vcf_file in enumerate(vcf_files):\n",
    "        vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "        for record in vcf_reader:\n",
    "            variant_key = f\"{record.CHROM}:{record.POS}:{record.REF}:{record.ALT[0]}\"\n",
    "            variant_counts[variant_key] += 1\n",
    "            if variant_counts[variant_key] == 1:\n",
    "                unique_variants[i].append(variant_key)\n",
    "            elif variant_counts[variant_key] > 1 and variant_key in unique_variants[i]:\n",
    "                unique_variants[i].remove(variant_key)\n",
    "    \n",
    "    return unique_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdca6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Annotate variants\n",
    "def annotate_variants(vcf_file, gene_file):\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    genes = SeqIO.to_dict(SeqIO.parse(gene_file, \"fasta\"))\n",
    "    \n",
    "    annotated_variants = []\n",
    "    for record in vcf_reader:\n",
    "        if record.CHROM in genes:\n",
    "            gene_seq = genes[record.CHROM].seq\n",
    "            pos = record.POS - 1  # 0-based indexing\n",
    "            codon_start = (pos // 3) * 3\n",
    "            ref_codon = gene_seq[codon_start:codon_start+3]\n",
    "            alt_codon = ref_codon[:pos%3] + record.ALT[0] + ref_codon[pos%3+1:]\n",
    "            \n",
    "            ref_aa = Seq(ref_codon).translate()\n",
    "            alt_aa = Seq(alt_codon).translate()\n",
    "            \n",
    "            if ref_aa == alt_aa:\n",
    "                effect = \"synonymous\"\n",
    "            elif alt_aa == '*':\n",
    "                effect = \"nonsense\"\n",
    "            else:\n",
    "                effect = \"missense\"\n",
    "            \n",
    "            annotated_variants.append({\n",
    "                'CHROM': record.CHROM,\n",
    "                'POS': record.POS,\n",
    "                'REF': record.REF,\n",
    "                'ALT': str(record.ALT[0]),\n",
    "                'EFFECT': effect\n",
    "            })\n",
    "    \n",
    "    return annotated_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22cf3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Generate consensus sequence\n",
    "def generate_consensus(reference_file, vcf_file):\n",
    "    reference = SeqIO.read(reference_file, \"fasta\")\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    \n",
    "    consensus = list(str(reference.seq))\n",
    "    for record in vcf_reader:\n",
    "        pos = record.POS - 1  # 0-based indexing\n",
    "        consensus[pos] = str(record.ALT[0])\n",
    "    \n",
    "    return ''.join(consensus)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8f105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Calculate transition/transversion ratio\n",
    "def calculate_ti_tv_ratio(vcf_file):\n",
    "    transitions = 0\n",
    "    transversions = 0\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    \n",
    "    for record in vcf_reader:\n",
    "        if len(record.REF) == 1 and len(record.ALT[0]) == 1:\n",
    "            if (record.REF, str(record.ALT[0])) in [('A','G'), ('G','A'), ('C','T'), ('T','C')]:\n",
    "                transitions += 1\n",
    "            else:\n",
    "                transversions += 1\n",
    "    \n",
    "    return transitions / transversions if transversions > 0 else float('inf')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f47c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Identify regions of high variant density\n",
    "def find_high_density_regions(vcf_file, window_size=1000, threshold=10):\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    variant_positions = defaultdict(list)\n",
    "    \n",
    "    for record in vcf_reader:\n",
    "        variant_positions[record.CHROM].append(record.POS)\n",
    "    \n",
    "    high_density_regions = []\n",
    "    for chrom, positions in variant_positions.items():\n",
    "        positions.sort()\n",
    "        for i in range(len(positions)):\n",
    "            window_start = positions[i]\n",
    "            window_end = window_start + window_size\n",
    "            variants_in_window = sum(1 for pos in positions[i:] if pos < window_end)\n",
    "            if variants_in_window >= threshold:\n",
    "                high_density_regions.append((chrom, window_start, window_end))\n",
    "    \n",
    "    return high_density_regions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74353e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Convert genomic coordinates to gene-relative coordinates\n",
    "def genomic_to_gene_coordinates(vcf_file, gene_file):\n",
    "    vcf_reader = vcf.Reader(open(vcf_file, 'r'))\n",
    "    genes = SeqIO.to_dict(SeqIO.parse(gene_file, \"fasta\"))\n",
    "    \n",
    "    converted_variants = []\n",
    "    for record in vcf_reader:\n",
    "        if record.CHROM in genes:\n",
    "            gene_start = genes[record.CHROM].features[0].location.start\n",
    "            gene_relative_pos = record.POS - gene_start\n",
    "            converted_variants.append({\n",
    "                'GENE': record.CHROM,\n",
    "                'GENE_POS': gene_relative_pos,\n",
    "                'REF': record.REF,\n",
    "                'ALT': str(record.ALT[0])\n",
    "            })\n",
    "    \n",
    "    return converted_variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a447f3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Simulate variant calling process\n",
    "def simulate_variant_calling(reference_sequence, read_length=100, coverage=30, error_rate=0.01):\n",
    "    # Generate mock reads\n",
    "    num_reads = int(len(reference_sequence) * coverage / read_length)\n",
    "    reads = []\n",
    "    for _ in range(num_reads):\n",
    "        start = random.randint(0, len(reference_sequence) - read_length)\n",
    "        read = list(reference_sequence[start:start+read_length])\n",
    "        for i in range(len(read)):\n",
    "            if random.random() < error_rate:\n",
    "                read[i] = random.choice(['A', 'C', 'G', 'T'])\n",
    "        reads.append(''.join(read))\n",
    "    \n",
    "    # Simple variant calling\n",
    "    base_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for read in reads:\n",
    "        for i, base in enumerate(read):\n",
    "            base_counts[i][base] += 1\n",
    "    \n",
    "    variants = []\n",
    "    for pos, counts in base_counts.items():\n",
    "        ref_base = reference_sequence[pos]\n",
    "        alt_bases = [base for base, count in counts.items() if base != ref_base and count > coverage/4]\n",
    "        if alt_bases:\n",
    "            variants.append({\n",
    "                'POS': pos,\n",
    "                'REF': ref_base,\n",
    "                'ALT': alt_bases[0]\n",
    "            })\n",
    "    \n",
    "    return variants\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e7b98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Implement a function to detect potential structural variants using a read-pair approach. The function should identify read pairs with abnormal insert sizes or orientations.\n",
    "import pysam\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def detect_structural_variants(bam_file, mean_insert_size, std_insert_size, min_support=3):\n",
    "    structural_variants = defaultdict(list)\n",
    "    \n",
    "    with pysam.AlignmentFile(bam_file, \"rb\") as bam:\n",
    "        for read in bam.fetch():\n",
    "            if read.is_proper_pair and not read.is_secondary and not read.is_supplementary:\n",
    "                if read.template_length > mean_insert_size + 3 * std_insert_size:\n",
    "                    sv_type = \"Deletion\"\n",
    "                    sv_size = abs(read.template_length) - mean_insert_size\n",
    "                elif read.template_length < mean_insert_size - 3 * std_insert_size:\n",
    "                    sv_type = \"Insertion\"\n",
    "                    sv_size = mean_insert_size - abs(read.template_length)\n",
    "                else:\n",
    "                    continue\n",
    "                \n",
    "                start = min(read.reference_start, read.next_reference_start)\n",
    "                end = max(read.reference_end, read.reference_start + abs(read.template_length))\n",
    "                \n",
    "                structural_variants[(read.reference_name, sv_type)].append((start, end, sv_size))\n",
    "    \n",
    "    # Filter by minimum support\n",
    "    filtered_svs = {}\n",
    "    for (chrom, sv_type), svs in structural_variants.items():\n",
    "        if len(svs) >= min_support:\n",
    "            filtered_svs[(chrom, sv_type)] = np.median(svs, axis=0)\n",
    "    \n",
    "    return filtered_svs\n",
    "\n",
    "# Example usage\n",
    "bam_file = \"example.bam\"\n",
    "mean_insert_size = 350\n",
    "std_insert_size = 50\n",
    "\n",
    "structural_variants = detect_structural_variants(bam_file, mean_insert_size, std_insert_size)\n",
    "\n",
    "for (chrom, sv_type), (start, end, size) in structural_variants.items():\n",
    "    print(f\"{chrom}\\t{sv_type}\\t{start:.0f}\\t{end:.0f}\\t{size:.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e72a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create a simple machine learning model (e.g., using scikit-learn) to classify variants as benign or pathogenic based on features like conservation scores and allele frequencies.\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def train_variant_classifier(data_file):\n",
    "    # Load data\n",
    "    data = pd.read_csv(data_file)\n",
    "    \n",
    "    # Prepare features and target\n",
    "    X = data.drop(['variant_id', 'class'], axis=1)\n",
    "    y = data['class']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Train model\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate model\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    return clf, scaler\n",
    "\n",
    "# Example usage\n",
    "data_file = \"variant_data.csv\"\n",
    "model, scaler = train_variant_classifier(data_file)\n",
    "\n",
    "# Classify new variants\n",
    "new_variants = pd.DataFrame({\n",
    "    'conservation_score': [0.8, 0.3, 0.9],\n",
    "    'allele_frequency': [0.001, 0.1, 0.0001],\n",
    "    'missense_score': [0.7, 0.2, 0.95]\n",
    "})\n",
    "\n",
    "new_variants_scaled = scaler.transform(new_variants)\n",
    "predictions = model.predict(new_variants_scaled)\n",
    "\n",
    "print(\"Predictions for new variants:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Develop a script to simulate the process of returning genetic results to participants, considering factors like variant pathogenicity, clinical actionability, and participant consent preferences.\n",
    "import random\n",
    "\n",
    "class GeneticResultsManager:\n",
    "    def __init__(self):\n",
    "        self.participants = {}\n",
    "        self.consent_levels = {\n",
    "            'all': ['pathogenic', 'likely_pathogenic', 'uncertain_significance', 'likely_benign', 'benign'],\n",
    "            'actionable': ['pathogenic', 'likely_pathogenic'],\n",
    "            'none': []\n",
    "        }\n",
    "    \n",
    "    def add_participant(self, participant_id, consent_level):\n",
    "        self.participants[participant_id] = {\n",
    "            'consent_level': consent_level,\n",
    "            'results': []\n",
    "        }\n",
    "    \n",
    "    def add_result(self, participant_id, variant, classification):\n",
    "        if participant_id in self.participants:\n",
    "            self.participants[participant_id]['results'].append({\n",
    "                'variant': variant,\n",
    "                'classification': classification\n",
    "            })\n",
    "    \n",
    "    def generate_report(self, participant_id):\n",
    "        if participant_id not in self.participants:\n",
    "            return f\"Participant {participant_id} not found.\"\n",
    "        \n",
    "        participant = self.participants[participant_id]\n",
    "        consent_level = participant['consent_level']\n",
    "        allowed_classifications = self.consent_levels[consent_level]\n",
    "        \n",
    "        report = f\"Genetic Results Report for Participant {participant_id}\\n\"\n",
    "        report += f\"Consent Level: {consent_level}\\n\\n\"\n",
    "        \n",
    "        for result in participant['results']:\n",
    "            if result['classification'] in allowed_classifications:\n",
    "                report += f\"Variant: {result['variant']}\\n\"\n",
    "                report += f\"Classification: {result['classification']}\\n\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# Example usage\n",
    "manager = GeneticResultsManager()\n",
    "\n",
    "# Add participants with different consent levels\n",
    "manager.add_participant('P001', 'all')\n",
    "manager.add_participant('P002', 'actionable')\n",
    "manager.add_participant('P003', 'none')\n",
    "\n",
    "# Simulate adding results\n",
    "variants = ['BRCA1:c.181T>G', 'TP53:c.215C>G', 'PTEN:c.388C>T']\n",
    "classifications = ['pathogenic', 'likely_pathogenic', 'uncertain_significance', 'likely_benign', 'benign']\n",
    "\n",
    "for participant in manager.participants:\n",
    "    for _ in range(3):\n",
    "        variant = random.choice(variants)\n",
    "        classification = random.choice(classifications)\n",
    "        manager.add_result(participant, variant, classification)\n",
    "\n",
    "# Generate and print reports\n",
    "for participant in manager.participants:\n",
    "    print(manager.generate_report(participant))\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437ae70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Implement a basic population stratification analysis to identify potential biases in a variant dataset, considering different ethnic groups or populations.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def population_stratification_analysis(genotype_data, population_labels):\n",
    "    # Perform PCA\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(genotype_data)\n",
    "    \n",
    "    # Create a dataframe with PCA results and population labels\n",
    "    result_df = pd.DataFrame(data=pca_result, columns=['PC1', 'PC2'])\n",
    "    result_df['Population'] = population_labels\n",
    "    \n",
    "    # Plot results\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    populations = result_df['Population'].unique()\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, len(populations)))\n",
    "    \n",
    "    for population, color in zip(populations, colors):\n",
    "        mask = result_df['Population'] == population\n",
    "        plt.scatter(result_df.loc[mask, 'PC1'], result_df.loc[mask, 'PC2'], \n",
    "                    c=[color], label=population, alpha=0.7)\n",
    "    \n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.legend()\n",
    "    plt.title('Population Stratification Analysis')\n",
    "    plt.savefig('population_stratification.png')\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Population stratification plot saved as 'population_stratification.png'\")\n",
    "    \n",
    "    # Calculate Fst (simplified version)\n",
    "    total_variance = np.var(genotype_data, axis=0)\n",
    "    within_population_variance = np.mean([np.var(genotype_data[population_labels == pop], axis=0) \n",
    "                                          for pop in populations], axis=0)\n",
    "    fst = (total_variance - within_population_variance) / total_variance\n",
    "    \n",
    "    return np.mean(fst)\n",
    "\n",
    "# Example usage\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "n_variants = 100\n",
    "\n",
    "# Simulate genotype data for three populations\n",
    "pop1 = np.random.binomial(2, 0.3, size=(n_samples // 3, n_variants))\n",
    "pop2 = np.random.binomial(2, 0.5, size=(n_samples // 3, n_variants))\n",
    "pop3 = np.random.binomial(2, 0.7, size=(n_samples // 3, n_variants))\n",
    "\n",
    "genotype_data = np.vstack((pop1, pop2, pop3))\n",
    "population_labels = np.repeat(['Pop1', 'Pop2', 'Pop3'], n_samples // 3)\n",
    "\n",
    "fst = population_stratification_analysis(genotype_data, population_labels)\n",
    "print(f\"Average Fst: {fst:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3832aac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Create a function to anonymize genetic data by replacing personally identifiable information with hash codes while preserving the ability to link related records.\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "def anonymize_genetic_data(data, identifiers, salt=\"\"):\n",
    "    anonymized_data = data.copy()\n",
    "    id_mapping = {}\n",
    "    \n",
    "    for identifier in identifiers:\n",
    "        if identifier in anonymized_data.columns:\n",
    "            anonymized_data[identifier] = anonymized_data[identifier].apply(\n",
    "                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()\n",
    "            )\n",
    "            \n",
    "            # Create a mapping to preserve links between related records\n",
    "            id_mapping[identifier] = dict(zip(data[identifier], anonymized_data[identifier]))\n",
    "    \n",
    "    return anonymized_data, id_mapping\n",
    "\n",
    "def link_related_records(anonymized_data, id_mapping, link_column):\n",
    "    linked_data = anonymized_data.copy()\n",
    "    \n",
    "    if link_column in id_mapping:\n",
    "        linked_data['original_' + link_column] = linked_data[link_column].map(\n",
    "            {v: k for k, v in id_mapping[link_column].items()}\n",
    "        )\n",
    "    \n",
    "    return linked_data\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame({\n",
    "    'patient_id': ['P001', 'P002', 'P003', 'P001', 'P002'],\n",
    "    'sample_id': ['S001', 'S002', 'S003', 'S004', 'S005'],\n",
    "    'age': [35, 42, 28, 35, 42],\n",
    "    'gender': ['M', 'F', 'M', 'M', 'F'],\n",
    "    'genotype': ['AA', 'AT', 'TT', 'AG', 'GG']\n",
    "})\n",
    "\n",
    "identifiers = ['patient_id', 'sample_id']\n",
    "anonymized_data, id_mapping = anonymize_genetic_data(data, identifiers)\n",
    "\n",
    "print(\"Anonymized data:\")\n",
    "print(anonymized_data)\n",
    "\n",
    "linked_data = link_related_records(anonymized_data, id_mapping, 'patient_id')\n",
    "\n",
    "print(\"\\nLinked data:\")\n",
    "print(linked_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8bb076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# variants = parse_vcf(\"example.vcf\")\n",
    "# allele_freqs = calculate_allele_frequencies(\"example.vcf\")\n",
    "# filtered_variants = filter_variants_by_quality(\"example.vcf\", 30)\n",
    "# unique_vars = find_unique_variants([\"sample1.vcf\", \"sample2.vcf\", \"sample3.vcf\"])\n",
    "# annotated_vars = annotate_variants(\"example.vcf\", \"genes.fasta\")\n",
    "# consensus = generate_consensus(\"reference.fasta\", \"variants.vcf\")\n",
    "# ti_tv_ratio = calculate_ti_tv_ratio(\"example.vcf\")\n",
    "# high_density = find_high_density_regions(\"example.vcf\")\n",
    "# gene_coords = genomic_to_gene_coordinates(\"example.vcf\", \"genes.fasta\")\n",
    "# simulated_variants = simulate_variant_calling(\"ATCGATCGATCG\" * 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
