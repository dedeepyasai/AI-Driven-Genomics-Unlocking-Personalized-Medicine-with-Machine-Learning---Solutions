{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ade9153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a636467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Count sequences in a FASTQ file\n",
    "def count_fastq_sequences(fastq_file):\n",
    "    count = 0\n",
    "    with gzip.open(fastq_file, \"rt\") if fastq_file.endswith(\".gz\") else open(fastq_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            count += 1\n",
    "    return count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b787ac47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Calculate GC content\n",
    "def calculate_gc_content(fasta_file):\n",
    "    gc_contents = []\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        sequence = str(record.seq).upper()\n",
    "        gc_content = (sequence.count('G') + sequence.count('C')) / len(sequence) * 100\n",
    "        gc_contents.append(gc_content)\n",
    "    return gc_contents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8f96b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Convert FASTQ to FASTA\n",
    "def fastq_to_fasta(fastq_file, fasta_file):\n",
    "    with open(fasta_file, \"w\") as output_handle:\n",
    "        SeqIO.convert(fastq_file, \"fastq\", output_handle, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433d16e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Find longest sequence in FASTA\n",
    "def find_longest_sequence(fasta_file):\n",
    "    return max(SeqIO.parse(fasta_file, \"fasta\"), key=lambda x: len(x.seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5769a4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Calculate N50\n",
    "def calculate_n50(fasta_file):\n",
    "    lengths = [len(record.seq) for record in SeqIO.parse(fasta_file, \"fasta\")]\n",
    "    lengths.sort(reverse=True)\n",
    "    total_length = sum(lengths)\n",
    "    cumulative_length = 0\n",
    "    for length in lengths:\n",
    "        cumulative_length += length\n",
    "        if cumulative_length >= total_length / 2:\n",
    "            return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70dc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Filter low-quality reads\n",
    "def filter_low_quality_reads(input_fastq, output_fastq, quality_threshold):\n",
    "    with open(output_fastq, \"w\") as output_handle:\n",
    "        for record in SeqIO.parse(input_fastq, \"fastq\"):\n",
    "            if min(record.letter_annotations[\"phred_quality\"]) >= quality_threshold:\n",
    "                SeqIO.write(record, output_handle, \"fastq\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c8bcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Compare two FASTA files\n",
    "def compare_fasta_files(fasta1, fasta2):\n",
    "    sequences1 = set(str(record.seq) for record in SeqIO.parse(fasta1, \"fasta\"))\n",
    "    sequences2 = set(str(record.seq) for record in SeqIO.parse(fasta2, \"fasta\"))\n",
    "    return sequences1.intersection(sequences2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8015e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Reverse complement\n",
    "def reverse_complement(sequence):\n",
    "    return str(Seq(sequence).reverse_complement())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d114472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Split FASTA file\n",
    "def split_fasta(input_fasta, output_prefix, sequences_per_file):\n",
    "    records = list(SeqIO.parse(input_fasta, \"fasta\"))\n",
    "    for i, batch in enumerate(range(0, len(records), sequences_per_file)):\n",
    "        with open(f\"{output_prefix}_{i+1}.fasta\", \"w\") as output_handle:\n",
    "            SeqIO.write(records[batch:batch+sequences_per_file], output_handle, \"fasta\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed37a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Calculate read length distribution\n",
    "def read_length_distribution(fastq_file):\n",
    "    lengths = [len(record.seq) for record in SeqIO.parse(fastq_file, \"fastq\")]\n",
    "    plt.hist(lengths, bins=50)\n",
    "    plt.title(\"Read Length Distribution\")\n",
    "    plt.xlabel(\"Read Length\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffa494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11.Implement a function to simulate long-read sequencing data, including typical error profiles:\n",
    "import numpy as np\n",
    "\n",
    "def simulate_long_reads(genome_length, read_length, coverage, error_rates):\n",
    "    num_reads = int((genome_length * coverage) / read_length)\n",
    "    reads = []\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    error_types = ['substitution', 'insertion', 'deletion']\n",
    "    \n",
    "    for _ in range(num_reads):\n",
    "        start = np.random.randint(0, genome_length - read_length)\n",
    "        read = ''.join(np.random.choice(bases, read_length))\n",
    "        \n",
    "        # Introduce errors\n",
    "        for i in range(read_length):\n",
    "            error_type = np.random.choice(error_types + ['no_error'], p=[error_rates['substitution'],\n",
    "                                                                         error_rates['insertion'],\n",
    "                                                                         error_rates['deletion'],\n",
    "                                                                         1 - sum(error_rates.values())])\n",
    "            if error_type == 'substitution':\n",
    "                read = read[:i] + np.random.choice([b for b in bases if b != read[i]]) + read[i+1:]\n",
    "            elif error_type == 'insertion':\n",
    "                read = read[:i] + np.random.choice(bases) + read[i:]\n",
    "            elif error_type == 'deletion':\n",
    "                read = read[:i] + read[i+1:]\n",
    "        \n",
    "        reads.append((start, read))\n",
    "    \n",
    "    return reads\n",
    "\n",
    "# Example usage\n",
    "genome_length = 1000000\n",
    "read_length = 10000\n",
    "coverage = 20\n",
    "error_rates = {'substitution': 0.01, 'insertion': 0.005, 'deletion': 0.005}\n",
    "\n",
    "simulated_reads = simulate_long_reads(genome_length, read_length, coverage, error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bede98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Create a simple genomic data compression algorithm using run-length encoding:\n",
    "def compress_genomic_sequence(sequence):\n",
    "    compressed = []\n",
    "    count = 1\n",
    "    current_base = sequence[0]\n",
    "    \n",
    "    for base in sequence[1:]:\n",
    "        if base == current_base:\n",
    "            count += 1\n",
    "        else:\n",
    "            compressed.append((current_base, count))\n",
    "            current_base = base\n",
    "            count = 1\n",
    "    \n",
    "    compressed.append((current_base, count))\n",
    "    return compressed\n",
    "\n",
    "def decompress_genomic_sequence(compressed):\n",
    "    return ''.join(base * count for base, count in compressed)\n",
    "\n",
    "# Example usage\n",
    "sequence = \"AAAATTCCCGGGGAAATTTCCCG\"\n",
    "compressed = compress_genomic_sequence(sequence)\n",
    "decompressed = decompress_genomic_sequence(compressed)\n",
    "\n",
    "print(f\"Original sequence: {sequence}\")\n",
    "print(f\"Compressed: {compressed}\")\n",
    "print(f\"Decompressed: {decompressed}\")\n",
    "print(f\"Compression ratio: {len(compressed) / len(sequence):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2a74af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13. Write a script to anonymize personal identifiers in a genomic dataset while preserving necessary metadata:\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "\n",
    "def anonymize_genomic_data(data, identifiers, salt=\"\"):\n",
    "    anonymized_data = data.copy()\n",
    "    \n",
    "    for identifier in identifiers:\n",
    "        if identifier in anonymized_data.columns:\n",
    "            anonymized_data[identifier] = anonymized_data[identifier].apply(\n",
    "                lambda x: hashlib.sha256((str(x) + salt).encode()).hexdigest()\n",
    "            )\n",
    "    \n",
    "    return anonymized_data\n",
    "\n",
    "# Example usage\n",
    "data = pd.DataFrame({\n",
    "    'patient_id': ['P001', 'P002', 'P003'],\n",
    "    'age': [35, 42, 28],\n",
    "    'gender': ['M', 'F', 'M'],\n",
    "    'genotype': ['AA', 'AT', 'TT']\n",
    "})\n",
    "\n",
    "identifiers = ['patient_id']\n",
    "anonymized_data = anonymize_genomic_data(data, identifiers)\n",
    "\n",
    "print(\"Original data:\")\n",
    "print(data)\n",
    "print(\"\\nAnonymized data:\")\n",
    "print(anonymized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69c184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14. Develop a function to calculate and visualize the quality scores distribution for a FASTQ file:\n",
    "from Bio import SeqIO\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_quality_scores(fastq_file):\n",
    "    quality_scores = []\n",
    "    \n",
    "    with open(fastq_file, \"r\") as handle:\n",
    "        for record in SeqIO.parse(handle, \"fastq\"):\n",
    "            quality_scores.extend(record.letter_annotations[\"phred_quality\"])\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(quality_scores, bins=40, edgecolor='black')\n",
    "    plt.title(\"Quality Scores Distribution\")\n",
    "    plt.xlabel(\"Phred Quality Score\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.savefig(\"quality_scores_distribution.png\")\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Quality scores distribution saved as 'quality_scores_distribution.png'\")\n",
    "\n",
    "# Example usage\n",
    "fastq_file = \"example.fastq\"\n",
    "visualize_quality_scores(fastq_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd6f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 15. Implement a basic error correction algorithm for long-read sequencing data:\n",
    "from collections import Counter\n",
    "\n",
    "def correct_errors(reads, k=21):\n",
    "    # Build k-mer frequency table\n",
    "    kmer_counts = Counter()\n",
    "    for read in reads:\n",
    "        for i in range(len(read) - k + 1):\n",
    "            kmer_counts[read[i:i+k]] += 1\n",
    "    \n",
    "    # Correct errors\n",
    "    corrected_reads = []\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    \n",
    "    for read in reads:\n",
    "        corrected_read = \"\"\n",
    "        for i in range(len(read)):\n",
    "            if i < k - 1:\n",
    "                corrected_read += read[i]\n",
    "            else:\n",
    "                kmer = read[i-k+1:i+1]\n",
    "                if kmer_counts[kmer] < 2:  # Potential error\n",
    "                    best_base = read[i]\n",
    "                    best_count = kmer_counts[kmer]\n",
    "                    for base in bases:\n",
    "                        new_kmer = kmer[:-1] + base\n",
    "                        if kmer_counts[new_kmer] > best_count:\n",
    "                            best_base = base\n",
    "                            best_count = kmer_counts[new_kmer]\n",
    "                    corrected_read += best_base\n",
    "                else:\n",
    "                    corrected_read += read[i]\n",
    "        \n",
    "        corrected_reads.append(corrected_read)\n",
    "    \n",
    "    return corrected_reads\n",
    "\n",
    "# Example usage\n",
    "reads = [\n",
    "    \"ACGTACGTACGTACGTACGTACGTACGTACGT\",\n",
    "    \"ACGTACGTACGTACGTACGTACGTACGTACGA\",\n",
    "    \"ACGTACGTACGTACGTACGTACGTACGTACGG\"\n",
    "]\n",
    "\n",
    "corrected_reads = correct_errors(reads)\n",
    "\n",
    "print(\"Original reads:\")\n",
    "print(reads)\n",
    "print(\"\\nCorrected reads:\")\n",
    "print(corrected_reads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfda270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "# count_fastq_sequences(\"example.fastq\")\n",
    "# calculate_gc_content(\"example.fasta\")\n",
    "# fastq_to_fasta(\"input.fastq\", \"output.fasta\")\n",
    "# longest_seq = find_longest_sequence(\"example.fasta\")\n",
    "# n50 = calculate_n50(\"example.fasta\")\n",
    "# filter_low_quality_reads(\"input.fastq\", \"output.fastq\", 20)\n",
    "# common_sequences = compare_fasta_files(\"file1.fasta\", \"file2.fasta\")\n",
    "# rev_comp = reverse_complement(\"ATGCATGC\")\n",
    "# split_fasta(\"large_file.fasta\", \"output\", 1000)\n",
    "# read_length_distribution(\"example.fastq\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
